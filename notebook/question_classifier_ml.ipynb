{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_eve/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import string as st\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import fasttext\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content in each cell\n",
    "pd.set_option('display.width', 1000)  # Set max width\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower().strip())  # Lowercase and remove whitespace\n",
    "    \n",
    "    # Remove stopwords, punctuation, and lemmatize\n",
    "    tokens = [token.lemma_ for token in doc \n",
    "             if not token.is_stop and not token.is_punct and token.is_alpha]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linguistic_features(text):\n",
    "    doc = nlp(text)\n",
    "    features = {\n",
    "        'num_verbs': len([token for token in doc if token.pos_ == 'VERB']),\n",
    "        'num_nouns': len([token for token in doc if token.pos_ == 'NOUN']),\n",
    "        'sentence_length': len(doc),\n",
    "        'blooms_verb_present': any(token.text in {'analyze', 'evaluate', 'create'} for token in doc)\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(text):\n",
    "    words = text.strip().split()\n",
    "    vectors = [model.get_word_vector(w) for w in words]\n",
    "    if not vectors:\n",
    "        return np.zeros(300)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapper = {\n",
    "    'BT1' : 'knowledge',\n",
    "    'BT2' : 'comprehension',\n",
    "    'BT3' : 'application',\n",
    "    'BT4' : 'analysis',\n",
    "    'BT5' : 'synthesis',\n",
    "    'BT6' : 'evaluation'\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    q_df = pd.read_csv(os.getcwd().replace('notebook' , 'dataset') + '/dataset' + str(i) + '.csv')\n",
    "    df = pd.concat([df , q_df])\n",
    "\n",
    "# Apply preprocessing\n",
    "mask = df['label'].isin(label_mapper.keys())\n",
    "df['label'] = df['label'].mask(mask, df['label'].map(label_mapper))\n",
    "df['label'] = df['label'].str.lower()\n",
    "\n",
    "df['processed_question'] = df['question'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "\n",
    "BERT model is used to retain context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT (TensorFlow version)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode\n",
    "inputs = tokenizer(df['question'].tolist(), return_tensors='tf', padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings (CLS token for sentence representation)\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "print(\"BERT Sentence Embedding Shape:\", sentence_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1000)\n",
    "reduced_embeddings = pca.fit_transform(sentence_embedding.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF \n",
    "Execute either BERT or IF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 1000)\n",
    "tfidf = vectorizer.fit_transform(df['processed_question'])\n",
    "\n",
    "# Convert TF-IDF sparse matrix to DataFrame with appropriate column names\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns= vectorizer.get_feature_names_out(), index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute if linguistic features like count for verb,noun,etc needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding linguistic features\n",
    "ling_features = df['processed_question'].apply(extract_linguistic_features).apply(pd.Series)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "token_df = pd.concat([ling_features, tfidf_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns (if needed)\n",
    "token_df = token_df.drop(columns=['blooms_verb_present'], axis=1)\n",
    "token_df.columns = token_df.columns.map(str)\n",
    "\n",
    "# token_df = pca.fit_transform(token_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = token_df , df['label']\n",
    "x_resampled , y_resampled = SMOTETomek().fit_resample(x , y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Machine Leanring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=34 , stratify= y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.801435</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.800956</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.799522</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.799462</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.799223</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.799044</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.798924</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.798864</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.798805</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.798685</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.797968</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.797669</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.797549</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.797490</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.796772</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.795995</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.795935</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.795696</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.795517</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.795397</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.790018</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.789121</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.788763</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.788524</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.787866</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.787448</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.786551</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.786073</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.784579</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.783921</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.779020</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.778123</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776689</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.776330</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.775792</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.774716</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.774656</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.774059</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.773640</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.772863</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.772744</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.771249</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.771010</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.766228</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.763598</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.755290</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.751763</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749851</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.748356</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.745786</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.744650</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.743814</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.743814</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.743634</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.742738</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.741901</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.741662</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.740526</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.717274</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.709623</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.690974</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.685953</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.685356</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.681530</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.673222</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.668559</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.668380</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.667484</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.666886</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.665810</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.665750</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.663658</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.663299</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.656904</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.654931</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.651405</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.646503</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.643096</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.624208</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.622176</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.613808</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.612194</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.609504</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.607113</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.591333</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.590377</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.589420</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.580096</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.574656</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.568380</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.566587</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.563359</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.553377</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.542080</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.522475</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.521399</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.502152</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.500359</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.496892</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.486432</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.484877</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.468201</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.407651</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.389540</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.380932</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.364435</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.304662</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.291931</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score                                                            params\n",
       "5           0.801435     {'criterion': 'gini', 'max_depth': None, 'n_estimators': 100}\n",
       "89          0.800956   {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 100}\n",
       "53          0.799522      {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 100}\n",
       "101         0.799462   {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 100}\n",
       "47          0.799223      {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 100}\n",
       "41          0.799044      {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 100}\n",
       "95          0.798924   {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 100}\n",
       "59          0.798864  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}\n",
       "40          0.798805       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 50}\n",
       "52          0.798685       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 50}\n",
       "107         0.797968   {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 100}\n",
       "88          0.797669    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 50}\n",
       "100         0.797549    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 50}\n",
       "35          0.797490      {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 100}\n",
       "94          0.796772    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 50}\n",
       "58          0.795995   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
       "4           0.795935      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
       "34          0.795696       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 50}\n",
       "106         0.795517    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 50}\n",
       "46          0.795397       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 50}\n",
       "93          0.790018    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 20}\n",
       "87          0.789121    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 20}\n",
       "105         0.788763    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 20}\n",
       "51          0.788524       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 20}\n",
       "3           0.787866      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}\n",
       "39          0.787448       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 20}\n",
       "45          0.786551       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 20}\n",
       "33          0.786073       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 20}\n",
       "99          0.784579    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 20}\n",
       "57          0.783921   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 20}\n",
       "50          0.779020       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 10}\n",
       "44          0.778123       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 10}\n",
       "2           0.776689      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
       "83          0.776330    {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}\n",
       "82          0.775792     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 50}\n",
       "56          0.774716   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
       "104         0.774656    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 10}\n",
       "86          0.774059    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 10}\n",
       "92          0.773640    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 10}\n",
       "98          0.772863    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 10}\n",
       "38          0.772744       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 10}\n",
       "32          0.771249       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 10}\n",
       "29          0.771010       {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100}\n",
       "28          0.766228        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 50}\n",
       "81          0.763598     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 20}\n",
       "27          0.755290        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 20}\n",
       "49          0.751763        {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 5}\n",
       "1           0.749851       {'criterion': 'gini', 'max_depth': None, 'n_estimators': 5}\n",
       "43          0.748356        {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 5}\n",
       "103         0.745786     {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 5}\n",
       "55          0.744650    {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 5}\n",
       "80          0.743814     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 10}\n",
       "31          0.743814        {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 5}\n",
       "97          0.743634     {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 5}\n",
       "26          0.742738        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 10}\n",
       "91          0.741901     {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 5}\n",
       "85          0.741662     {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 5}\n",
       "37          0.740526        {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 5}\n",
       "79          0.717274      {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 5}\n",
       "25          0.709623         {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 5}\n",
       "77          0.690974    {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}\n",
       "76          0.685953     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 50}\n",
       "23          0.685356       {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 100}\n",
       "22          0.681530        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 50}\n",
       "0           0.673222       {'criterion': 'gini', 'max_depth': None, 'n_estimators': 2}\n",
       "30          0.668559        {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 2}\n",
       "84          0.668380     {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 2}\n",
       "21          0.667484        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 20}\n",
       "75          0.666886     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 20}\n",
       "36          0.665810        {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 2}\n",
       "42          0.665750        {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 2}\n",
       "48          0.663658        {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 2}\n",
       "102         0.663299     {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 2}\n",
       "90          0.656904     {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 2}\n",
       "54          0.654931    {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 2}\n",
       "96          0.651405     {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 2}\n",
       "74          0.646503     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 10}\n",
       "20          0.643096        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 10}\n",
       "78          0.624208      {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 2}\n",
       "24          0.622176         {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 2}\n",
       "17          0.613808       {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}\n",
       "71          0.612194    {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}\n",
       "70          0.609504     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 50}\n",
       "16          0.607113        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50}\n",
       "73          0.591333      {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 5}\n",
       "19          0.590377         {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 5}\n",
       "69          0.589420     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20}\n",
       "15          0.580096        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 20}\n",
       "11          0.574656        {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}\n",
       "68          0.568380     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 10}\n",
       "65          0.566587     {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}\n",
       "14          0.563359        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 10}\n",
       "10          0.553377         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 50}\n",
       "64          0.542080      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 50}\n",
       "9           0.522475         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 20}\n",
       "63          0.521399      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 20}\n",
       "13          0.502152         {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 5}\n",
       "72          0.500359      {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 2}\n",
       "18          0.496892         {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 2}\n",
       "67          0.486432      {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 5}\n",
       "8           0.484877         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 10}\n",
       "62          0.468201      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 10}\n",
       "7           0.407651          {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}\n",
       "66          0.389540      {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 2}\n",
       "61          0.380932       {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}\n",
       "12          0.364435         {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 2}\n",
       "6           0.304662          {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 2}\n",
       "60          0.291931       {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators' : [2 , 5 , 10 , 20 , 50 , 100],\n",
    "    'criterion' : ['gini' , 'entropy'],\n",
    "    'max_depth' : [None , 5 , 10 , 20 , 50 , 100 , 200 , 350 , 500]\n",
    "}\n",
    "param_search = GridSearchCV(estimator= RandomForestClassifier(), param_grid= params, cv=5)\n",
    "\n",
    "param_search.fit(x_resampled , y_resampled)\n",
    "\n",
    "cv_results = pd.DataFrame(param_search.cv_results_)\n",
    "cv_results = cv_results[[\"mean_test_score\", \"params\"]].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "cv_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     analysis       0.90      0.88      0.89       564\n",
      "  application       0.90      0.89      0.90       564\n",
      "comprehension       0.84      0.83      0.83       554\n",
      "   evaluation       0.81      0.78      0.79       559\n",
      "    knowledge       0.74      0.80      0.77       547\n",
      "    synthesis       0.79      0.80      0.79       558\n",
      "\n",
      "     accuracy                           0.83      3346\n",
      "    macro avg       0.83      0.83      0.83      3346\n",
      " weighted avg       0.83      0.83      0.83      3346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators= 100 , max_depth= None , criterion= 'gini')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application']\n"
     ]
    }
   ],
   "source": [
    "question = 'How many total disk access is needed to search a record using two level indexing?'\n",
    "processed_q = preprocess_text(question)\n",
    "tfidf_q = vectorizer.transform([processed_q])\n",
    "tfidf_q = pd.DataFrame(tfidf_q.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# Adding linguistic features\n",
    "q_ling_features = pd.DataFrame([extract_linguistic_features(question)])\n",
    "\n",
    "# Concatenate DataFrames\n",
    "token_q = pd.concat([q_ling_features, tfidf_q], axis=1)\n",
    "token_q = token_q.drop(columns= ['blooms_verb_present'])\n",
    "\n",
    "print(classifier.predict(token_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How many total disk access is needed to search a record using two level indexing?'\n",
    "inputs =  tokenizer([question], return_tensors='tf', padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings (CLS token for sentence representation)\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.733831</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.733293</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.733054</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.732995</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.732636</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.732337</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731201</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.730544</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.730245</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.730006</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.730006</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729468</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.729468</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.728990</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.728571</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.728512</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.727675</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.725941</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.725762</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.724985</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.723192</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.723132</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.722355</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.719546</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.718470</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.718171</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.717454</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717095</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.716856</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.716557</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.715720</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.715421</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.715063</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.713927</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.710520</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.710042</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.708607</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.708249</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.707233</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.702630</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.701435</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.700658</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.699522</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.699103</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.697490</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.694082</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.689659</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.686372</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.684937</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.683981</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.683802</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.683503</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.681769</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.680634</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.679857</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.679259</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.678183</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.677884</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.677346</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.676987</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.673580</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.671488</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.669337</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.659295</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.656545</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.648834</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.647699</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.646145</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.646085</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.645487</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.639749</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.628870</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.555888</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.553437</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.551166</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.545666</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.539151</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.532636</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.529109</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.528452</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.526061</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.525822</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.523551</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.519187</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.424088</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.423849</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.422714</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.421578</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.420622</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.417932</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.417872</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.417633</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.416557</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.415959</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.415780</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.413150</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.336701</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.336701</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.336701</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.336581</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.336581</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.336402</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.331201</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.331142</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.331142</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.331082</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.330962</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.330663</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score                                                                 params\n",
       "54          0.733831    {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}\n",
       "48          0.733293        {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2}\n",
       "90          0.733054     {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 2}\n",
       "102         0.732995     {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2}\n",
       "42          0.732636        {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 2}\n",
       "43          0.732337        {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 5}\n",
       "0           0.731201       {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
       "36          0.730544        {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 2}\n",
       "91          0.730245     {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 5}\n",
       "49          0.730006        {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5}\n",
       "96          0.730006     {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 2}\n",
       "1           0.729468       {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}\n",
       "97          0.729468     {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 5}\n",
       "103         0.728990     {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5}\n",
       "37          0.728571        {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 5}\n",
       "55          0.728512    {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5}\n",
       "84          0.727675     {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2}\n",
       "30          0.725941        {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2}\n",
       "85          0.725762     {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5}\n",
       "2           0.724985      {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}\n",
       "38          0.723192       {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 10}\n",
       "44          0.723132       {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 10}\n",
       "31          0.722355        {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5}\n",
       "50          0.719546       {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10}\n",
       "104         0.718470    {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10}\n",
       "98          0.718171    {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 10}\n",
       "56          0.717454   {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10}\n",
       "3           0.717095      {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 20}\n",
       "92          0.716856    {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 10}\n",
       "45          0.716557       {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 20}\n",
       "51          0.715720       {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 20}\n",
       "39          0.715421       {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 20}\n",
       "32          0.715063       {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10}\n",
       "86          0.713927    {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10}\n",
       "57          0.710520   {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20}\n",
       "105         0.710042    {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 20}\n",
       "93          0.708607    {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 20}\n",
       "99          0.708249    {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 20}\n",
       "33          0.707233       {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 20}\n",
       "87          0.702630    {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 20}\n",
       "4           0.701435      {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 50}\n",
       "78          0.700658      {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2}\n",
       "52          0.699522       {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 50}\n",
       "46          0.699103       {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 50}\n",
       "40          0.697490       {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 50}\n",
       "79          0.694082      {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5}\n",
       "34          0.689659       {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 50}\n",
       "80          0.686372     {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10}\n",
       "58          0.684937   {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 50}\n",
       "100         0.683981    {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 50}\n",
       "94          0.683802    {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 50}\n",
       "24          0.683503         {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2}\n",
       "106         0.681769    {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 50}\n",
       "25          0.680634         {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5}\n",
       "81          0.679857     {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 20}\n",
       "88          0.679259    {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 50}\n",
       "47          0.678183      {'criterion': 'gini', 'max_depth': 350, 'min_samples_split': 100}\n",
       "41          0.677884      {'criterion': 'gini', 'max_depth': 200, 'min_samples_split': 100}\n",
       "53          0.677346      {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 100}\n",
       "5           0.676987     {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 100}\n",
       "26          0.673580        {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10}\n",
       "27          0.671488        {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 20}\n",
       "35          0.669337      {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 100}\n",
       "82          0.659295     {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 50}\n",
       "28          0.656545        {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 50}\n",
       "95          0.648834   {'criterion': 'entropy', 'max_depth': 200, 'min_samples_split': 100}\n",
       "59          0.647699  {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 100}\n",
       "101         0.646145   {'criterion': 'entropy', 'max_depth': 350, 'min_samples_split': 100}\n",
       "107         0.646085   {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 100}\n",
       "89          0.645487   {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 100}\n",
       "29          0.639749       {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 100}\n",
       "83          0.628870    {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 100}\n",
       "72          0.555888      {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2}\n",
       "73          0.553437      {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 5}\n",
       "74          0.551166     {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10}\n",
       "75          0.545666     {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20}\n",
       "76          0.539151     {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 50}\n",
       "18          0.532636         {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}\n",
       "19          0.529109         {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 5}\n",
       "20          0.528452        {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10}\n",
       "21          0.526061        {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20}\n",
       "77          0.525822    {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 100}\n",
       "22          0.523551        {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 50}\n",
       "23          0.519187       {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 100}\n",
       "66          0.424088      {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}\n",
       "67          0.423849      {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5}\n",
       "68          0.422714     {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10}\n",
       "69          0.421578     {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20}\n",
       "70          0.420622     {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 50}\n",
       "13          0.417932         {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}\n",
       "12          0.417872         {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2}\n",
       "14          0.417633        {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10}\n",
       "15          0.416557        {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}\n",
       "16          0.415959        {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 50}\n",
       "71          0.415780    {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 100}\n",
       "17          0.413150       {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 100}\n",
       "60          0.336701       {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
       "62          0.336701      {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
       "61          0.336701       {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
       "63          0.336581      {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20}\n",
       "64          0.336581      {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 50}\n",
       "65          0.336402     {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 100}\n",
       "10          0.331201         {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 50}\n",
       "7           0.331142          {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
       "6           0.331142          {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
       "9           0.331082         {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20}\n",
       "8           0.330962         {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
       "11          0.330663        {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 100}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'min_samples_split' : [2 , 5 , 10 , 20 , 50 , 100],\n",
    "    'criterion' : ['gini' , 'entropy'],\n",
    "    'max_depth' : [None , 5 , 10 , 20 , 50 , 100 , 200 , 350 , 500]\n",
    "    # 'min_samples_leaf' : [1 ,2 , 5 , 10 , 20 , 50 , 100]\n",
    "}\n",
    "param_search = GridSearchCV(estimator= DecisionTreeClassifier(), param_grid= params, cv=5)\n",
    "\n",
    "param_search.fit(x_resampled , y_resampled)\n",
    "\n",
    "cv_results = pd.DataFrame(param_search.cv_results_)\n",
    "cv_results = cv_results[[\"mean_test_score\", \"params\"]].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "cv_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     analysis       0.80      0.83      0.82       564\n",
      "  application       0.82      0.82      0.82       564\n",
      "comprehension       0.78      0.79      0.78       554\n",
      "   evaluation       0.74      0.75      0.74       559\n",
      "    knowledge       0.71      0.70      0.70       547\n",
      "    synthesis       0.73      0.69      0.71       558\n",
      "\n",
      "     accuracy                           0.76      3346\n",
      "    macro avg       0.76      0.76      0.76      3346\n",
      " weighted avg       0.76      0.76      0.76      3346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion= 'entropy', max_depth= None, min_samples_split = 2)\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comprehension']\n"
     ]
    }
   ],
   "source": [
    "question = 'How many total disk access is needed to search a record using two level indexing?'\n",
    "processed_q = preprocess_text(question)\n",
    "tfidf_q = vectorizer.transform([processed_q])\n",
    "tfidf_q = pd.DataFrame(tfidf_q.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# Adding linguistic features\n",
    "q_ling_features = pd.DataFrame([extract_linguistic_features(question)])\n",
    "\n",
    "# Concatenate DataFrames\n",
    "token_q = pd.concat([q_ling_features, tfidf_q], axis=1)\n",
    "token_q = token_q.drop(columns= ['blooms_verb_present'])\n",
    "\n",
    "print(dt.predict(token_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapper = {\n",
    "    'knowledge' : 0,\n",
    "    'comprehension' : 1,\n",
    "    'application' : 2,\n",
    "    'analysis' : 3,\n",
    "    'synthesis' : 4,\n",
    "    'evaluation' : 5\n",
    "}\n",
    "xgb_y = y_resampled.map(y_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.792542</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.792422</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.792363</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.791826</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.791050</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.791050</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.790990</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.790155</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.790036</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.790036</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.789797</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.789797</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.789737</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.789678</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.789618</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.789499</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.789379</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.788126</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.787947</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.787828</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.787828</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.787649</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.787649</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.787351</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.787112</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.786993</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.786933</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.786874</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.786516</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.786337</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.786217</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.786158</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.786038</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.785919</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.785800</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.785800</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.785621</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.785382</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.785382</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.785322</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.784308</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.783294</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.782041</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.780907</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.780131</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.778640</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.778341</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.777983</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.777864</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.777446</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.776193</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.775298</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.774642</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.773449</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.771957</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.771718</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.770525</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.770465</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.770227</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.770167</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.770167</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.769928</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.769630</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.768258</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.768019</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.765513</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.764618</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.764379</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.763842</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.763365</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.760263</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.757757</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.757757</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.756862</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.755967</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.755967</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.755072</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.753759</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.752148</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.751790</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.751253</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.751253</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.747792</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.747673</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.747673</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.747255</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.746778</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.746718</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.746599</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.746599</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.745286</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.744630</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.743437</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.743437</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.741647</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.741050</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.739916</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.739797</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.739439</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.738723</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.737411</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.736993</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.732100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.732100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.731086</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.729057</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.729057</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.728699</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.728461</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.727267</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.727267</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.724463</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.723628</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.721838</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.721838</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.721480</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.720704</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.719630</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.718854</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.718258</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.713365</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.711933</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.710919</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.707100</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.696420</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.694630</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.687470</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.679654</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.677864</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.676432</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.675119</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.665155</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.659069</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.657697</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.652566</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.648210</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.647017</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.634905</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.632518</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.630430</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.628640</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.621897</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.618496</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.611874</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.610859</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.606026</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.601014</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.597434</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.593258</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.591945</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.591169</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.577685</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.575716</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.572554</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.571957</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.569988</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.558055</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.557339</td>\n",
       "      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.555728</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.552924</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542363</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.539797</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535143</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.530310</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.523389</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.521659</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.516587</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.507518</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score                                                                                          params\n",
       "111         0.792542     {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "71          0.792422    {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "119         0.792363    {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "113         0.791826    {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "112         0.791050    {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "118         0.791050    {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "77          0.790990    {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "83          0.790155    {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "105         0.790036      {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "123         0.790036     {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "125         0.789797    {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "117         0.789797     {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "124         0.789737    {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "82          0.789678    {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "70          0.789618    {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "76          0.789499    {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "65          0.789379     {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "106         0.788126     {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "153         0.787947       {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "160         0.787828      {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "107         0.787828     {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "64          0.787649     {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "154         0.787649      {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "159         0.787351       {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "161         0.787112      {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "167         0.786993      {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "155         0.786933      {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "166         0.786874      {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "147         0.786516        {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "165         0.786337       {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "152         0.786217       {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "69          0.786158     {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "75          0.786038     {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "81          0.785919     {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "116         0.785800     {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "122         0.785800     {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "149         0.785621       {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "148         0.785382       {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "158         0.785382       {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "110         0.785322     {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "164         0.784308       {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "101         0.783294     {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "63          0.782041      {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "146         0.780907        {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "104         0.780131      {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "163         0.778640        {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "143         0.778341       {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "157         0.777983        {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "100         0.777864     {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "151         0.777446        {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "142         0.776193       {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "89          0.775298   {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "131         0.774642     {'learning_rate': 1, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "95          0.773449      {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "137         0.771957        {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "109         0.771718      {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "35          0.770525   {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "41          0.770465   {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "121         0.770227      {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "115         0.770167      {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "141         0.770167        {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "145         0.769928         {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "130         0.769630     {'learning_rate': 1, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "29          0.768258   {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "103         0.768019       {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "99          0.765513      {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "59          0.764618     {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "23          0.764379    {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "88          0.763842   {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "136         0.763365        {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "94          0.760263      {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "34          0.757757   {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "40          0.757757   {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "129         0.756862      {'learning_rate': 1, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "80          0.755967     {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "74          0.755967     {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "28          0.755072   {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "68          0.753759     {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "162         0.752148        {'learning_rate': 1, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "156         0.751790        {'learning_rate': 1, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "22          0.751253    {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "62          0.751253      {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "150         0.747792        {'learning_rate': 1, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "33          0.747673    {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "39          0.747673    {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "135         0.747255         {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "58          0.746778     {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "87          0.746718    {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "73          0.746599      {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "79          0.746599      {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "27          0.745286    {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "67          0.744630      {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "114         0.743437      {'learning_rate': 0.5, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "120         0.743437      {'learning_rate': 0.5, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "108         0.741647      {'learning_rate': 0.5, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "144         0.741050         {'learning_rate': 1, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "102         0.739916       {'learning_rate': 0.5, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "93          0.739797       {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "47          0.739439   {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "21          0.738723     {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "61          0.737411       {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "140         0.736993        {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "72          0.732100      {'learning_rate': 0.1, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "78          0.732100      {'learning_rate': 0.1, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "66          0.731086      {'learning_rate': 0.1, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "32          0.729057    {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "38          0.729057    {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "26          0.728699    {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "53          0.728461      {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "37          0.727267     {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "31          0.727267     {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "25          0.724463     {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "60          0.723628       {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "36          0.721838     {'learning_rate': 0.01, 'max_depth': 500, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "30          0.721838     {'learning_rate': 0.01, 'max_depth': 200, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "20          0.721480     {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "57          0.720704      {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "24          0.719630     {'learning_rate': 0.01, 'max_depth': 100, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "98          0.718854      {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "19          0.718258      {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "18          0.713365      {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "139         0.711933         {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "46          0.710919   {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "128         0.707100      {'learning_rate': 1, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "52          0.696420      {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "134         0.694630         {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "97          0.687470       {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "86          0.679654    {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "127         0.677864       {'learning_rate': 1, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "17          0.676432    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "45          0.675119    {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "92          0.665155       {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "51          0.659069       {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "133         0.657697          {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "138         0.652566         {'learning_rate': 1, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "56          0.648210      {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "16          0.647017    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "85          0.634905     {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "96          0.632518       {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "15          0.630430     {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "55          0.628640       {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "5           0.621897  {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "91          0.618496        {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "14          0.611874     {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "54          0.610859       {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "13          0.606026      {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "11          0.601014     {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softprob'}\n",
       "12          0.597434      {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "126         0.593258       {'learning_rate': 1, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "4           0.591945  {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "44          0.591169    {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "10          0.577685     {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
       "50          0.575716       {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "3           0.572554   {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "43          0.571957     {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "84          0.569988     {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "9           0.558055      {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'objective': 'multi:softprob'}\n",
       "132         0.557339          {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "90          0.555728        {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "49          0.552924        {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "2           0.542363   {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "42          0.539797     {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "1           0.535143    {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "0           0.530310    {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "8           0.523389      {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 10, 'objective': 'multi:softprob'}\n",
       "48          0.521659        {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}\n",
       "7           0.516587       {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5, 'objective': 'multi:softprob'}\n",
       "6           0.507518       {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 2, 'objective': 'multi:softprob'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'objective' : ['multi:softprob'],\n",
    "    'max_depth' : [None , 5 , 10 , 50 , 100 , 200 , 500],\n",
    "    'n_estimators': [2 , 5 , 10 , 50 , 100, 200],\n",
    "    'learning_rate': [0.01, 0.1 , 0.5, 1]\n",
    "    # 'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "param_search = GridSearchCV(estimator= XGBClassifier(), param_grid= params, cv=5)\n",
    "\n",
    "param_search.fit(x_resampled , xgb_y)\n",
    "\n",
    "cv_results = pd.DataFrame(param_search.cv_results_)\n",
    "cv_results = cv_results[[\"mean_test_score\", \"params\"]].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "cv_results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_eve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
