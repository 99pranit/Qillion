{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import string as st\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import fasttext\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content in each cell\n",
    "pd.set_option('display.width', 1000)  # Set max width\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower().strip())  # Lowercase and remove whitespace\n",
    "    \n",
    "    # Remove stopwords, punctuation, and lemmatize\n",
    "    tokens = [token.lemma_ for token in doc \n",
    "             if not token.is_stop and not token.is_punct and token.is_alpha]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linguistic_features(text):\n",
    "    doc = nlp(text)\n",
    "    features = {\n",
    "        'num_verbs': len([token for token in doc if token.pos_ == 'VERB']),\n",
    "        'num_nouns': len([token for token in doc if token.pos_ == 'NOUN']),\n",
    "        'sentence_length': len(doc),\n",
    "        'blooms_verb_present': any(token.text in {'analyze', 'evaluate', 'create'} for token in doc)\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(text):\n",
    "    words = text.strip().split()\n",
    "    vectors = [model.get_word_vector(w) for w in words]\n",
    "    if not vectors:\n",
    "        return np.zeros(300)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapper = {\n",
    "    'BT1' : 'knowledge',\n",
    "    'BT2' : 'comprehension',\n",
    "    'BT3' : 'application',\n",
    "    'BT4' : 'analysis',\n",
    "    'BT5' : 'synthesis',\n",
    "    'BT6' : 'evaluation'\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    q_df = pd.read_csv(os.getcwd().replace('notebook' , 'dataset') + '/dataset' + str(i) + '.csv')\n",
    "    df = pd.concat([df , q_df])\n",
    "\n",
    "# Apply preprocessing\n",
    "mask = df['label'].isin(label_mapper.keys())\n",
    "df['label'] = df['label'].mask(mask, df['label'].map(label_mapper))\n",
    "df['label'] = df['label'].str.lower()\n",
    "\n",
    "df['processed_question'] = df['question'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "\n",
    "BERT model is used to retain context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT (TensorFlow version)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode\n",
    "inputs = tokenizer(df['question'].tolist(), return_tensors='tf', padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings (CLS token for sentence representation)\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "print(\"BERT Sentence Embedding Shape:\", sentence_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "reduced_embeddings = pca.fit_transform(sentence_embedding.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF \n",
    "Execute either BERT or IF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 1000)\n",
    "tfidf = vectorizer.fit_transform(df['processed_question'])\n",
    "\n",
    "# Convert TF-IDF sparse matrix to DataFrame with appropriate column names\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns= vectorizer.get_feature_names_out(), index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute if linguistic features like count for verb,noun,etc needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding linguistic features\n",
    "ling_features = df['processed_question'].apply(extract_linguistic_features).apply(pd.Series)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "token_df = pd.concat([ling_features, tfidf_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns (if needed)\n",
    "token_df = token_df.drop(columns=['blooms_verb_present'], axis=1)\n",
    "token_df.columns = token_df.columns.map(str)\n",
    "\n",
    "# token_df = pca.fit_transform(token_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = tfidf_df , df['label']\n",
    "x_resampled , y_resampled = SMOTETomek().fit_resample(x , y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Machine Leanring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=34 , stratify= y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.793406</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.792196</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.791954</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.791712</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.790502</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.790442</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.790260</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.790200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.789655</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.789232</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.789171</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.787659</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.786993</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786691</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.786025</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.785178</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.784392</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.783303</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.780762</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.780641</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.779976</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.779976</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.779492</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.776407</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.774410</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.774168</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.771869</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.771567</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.771567</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.771506</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.770599</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.769510</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.769449</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.767574</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.766909</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.766727</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.763702</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.761101</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756080</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.753902</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.752813</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.751785</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.751664</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.749667</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.748457</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.747368</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.744404</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.740290</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.738959</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.738355</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.731216</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.730732</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.729764</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.724803</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.724259</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.717665</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.715245</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.702057</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.692075</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 350, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.688082</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 500, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.687961</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.686691</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 200, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.685057</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.681851</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680399</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.675318</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.671446</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.668179</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.663521</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.663521</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.650454</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.647187</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.632063</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.630974</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.625650</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.618330</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.613309</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.591289</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.589353</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.581791</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.579915</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.578887</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.572595</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.570417</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.559589</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.557411</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.552934</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.548699</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.543557</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.535330</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.530611</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.527102</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.516697</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.496794</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.491107</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.484332</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.455898</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.452269</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.441137</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.438355</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.424017</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.421658</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.366727</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.351664</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.339625</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.321113</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.261041</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.255233</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score                                                            params\n",
       "107         0.793406   {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 100}\n",
       "59          0.792196  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}\n",
       "47          0.791954      {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 100}\n",
       "101         0.791712   {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 100}\n",
       "5           0.790502     {'criterion': 'gini', 'max_depth': None, 'n_estimators': 100}\n",
       "95          0.790442   {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 100}\n",
       "58          0.790260   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
       "100         0.790200    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 50}\n",
       "106         0.789655    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 50}\n",
       "46          0.789232       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 50}\n",
       "53          0.789171      {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 100}\n",
       "52          0.787659       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 50}\n",
       "94          0.786993    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 50}\n",
       "4           0.786691      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
       "99          0.786025    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 20}\n",
       "105         0.785178    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 20}\n",
       "41          0.784392      {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 100}\n",
       "40          0.783303       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 50}\n",
       "3           0.780762      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}\n",
       "51          0.780641       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 20}\n",
       "57          0.779976   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 20}\n",
       "93          0.779976    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 20}\n",
       "45          0.779492       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 20}\n",
       "39          0.776407       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 20}\n",
       "89          0.774410   {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 100}\n",
       "104         0.774168    {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 10}\n",
       "35          0.771869      {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 100}\n",
       "98          0.771567    {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 10}\n",
       "88          0.771567    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 50}\n",
       "50          0.771506       {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 10}\n",
       "56          0.770599   {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
       "44          0.769510       {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 10}\n",
       "38          0.769449       {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 10}\n",
       "92          0.767574    {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 10}\n",
       "2           0.766909      {'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
       "34          0.766727       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 50}\n",
       "87          0.763702    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 20}\n",
       "33          0.761101       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 20}\n",
       "1           0.756080       {'criterion': 'gini', 'max_depth': None, 'n_estimators': 5}\n",
       "32          0.753902       {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 10}\n",
       "43          0.752813        {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 5}\n",
       "49          0.751785        {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 5}\n",
       "86          0.751664    {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 10}\n",
       "97          0.749667     {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 5}\n",
       "103         0.748457     {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 5}\n",
       "55          0.747368    {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 5}\n",
       "91          0.744404     {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 5}\n",
       "37          0.740290        {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 5}\n",
       "83          0.738959    {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}\n",
       "82          0.738355     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 50}\n",
       "85          0.731216     {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 5}\n",
       "28          0.730732        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 50}\n",
       "29          0.729764       {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100}\n",
       "31          0.724803        {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 5}\n",
       "81          0.724259     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 20}\n",
       "27          0.717665        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 20}\n",
       "80          0.715245     {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 10}\n",
       "26          0.702057        {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 10}\n",
       "42          0.692075        {'criterion': 'gini', 'max_depth': 350, 'n_estimators': 2}\n",
       "48          0.688082        {'criterion': 'gini', 'max_depth': 500, 'n_estimators': 2}\n",
       "90          0.687961     {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 2}\n",
       "36          0.686691        {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 2}\n",
       "54          0.685057    {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 2}\n",
       "96          0.681851     {'criterion': 'entropy', 'max_depth': 350, 'n_estimators': 2}\n",
       "0           0.680399       {'criterion': 'gini', 'max_depth': None, 'n_estimators': 2}\n",
       "102         0.675318     {'criterion': 'entropy', 'max_depth': 500, 'n_estimators': 2}\n",
       "79          0.671446      {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 5}\n",
       "84          0.668179     {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 2}\n",
       "30          0.663521        {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 2}\n",
       "25          0.663521         {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 5}\n",
       "77          0.650454    {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}\n",
       "23          0.647187       {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 100}\n",
       "76          0.632063     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 50}\n",
       "21          0.630974        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 20}\n",
       "22          0.625650        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 50}\n",
       "75          0.618330     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 20}\n",
       "74          0.613309     {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 10}\n",
       "78          0.591289      {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 2}\n",
       "20          0.589353        {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 10}\n",
       "70          0.581791     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 50}\n",
       "71          0.579915    {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}\n",
       "17          0.578887       {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}\n",
       "16          0.572595        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50}\n",
       "24          0.570417         {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 2}\n",
       "15          0.559589        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 20}\n",
       "19          0.557411         {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 5}\n",
       "69          0.552934     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20}\n",
       "73          0.548699      {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 5}\n",
       "11          0.543557        {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}\n",
       "65          0.535330     {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}\n",
       "64          0.530611      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 50}\n",
       "10          0.527102         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 50}\n",
       "14          0.516697        {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 10}\n",
       "68          0.496794     {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 10}\n",
       "63          0.491107      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 20}\n",
       "9           0.484332         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 20}\n",
       "13          0.455898         {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 5}\n",
       "72          0.452269      {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 2}\n",
       "67          0.441137      {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 5}\n",
       "62          0.438355      {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 10}\n",
       "8           0.424017         {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 10}\n",
       "18          0.421658         {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 2}\n",
       "61          0.366727       {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}\n",
       "12          0.351664         {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 2}\n",
       "7           0.339625          {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}\n",
       "66          0.321113      {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 2}\n",
       "6           0.261041          {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 2}\n",
       "60          0.255233       {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 2}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators' : [2 , 5 , 10 , 20 , 50 , 100],\n",
    "    'criterion' : ['gini' , 'entropy'],\n",
    "    'max_depth' : [None , 5 , 10 , 20 , 50 , 100 , 200 , 350 , 500]\n",
    "}\n",
    "param_search = GridSearchCV(estimator= RandomForestClassifier(), param_grid= params, cv=5)\n",
    "\n",
    "param_search.fit(x_resampled , y_resampled)\n",
    "\n",
    "cv_results = pd.DataFrame(param_search.cv_results_)\n",
    "cv_results = cv_results[[\"mean_test_score\", \"params\"]].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "cv_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     analysis       0.87      0.84      0.86       562\n",
      "  application       0.90      0.88      0.89       564\n",
      "comprehension       0.82      0.86      0.84       551\n",
      "   evaluation       0.78      0.76      0.77       541\n",
      "    knowledge       0.76      0.78      0.77       547\n",
      "    synthesis       0.75      0.75      0.75       541\n",
      "\n",
      "     accuracy                           0.81      3306\n",
      "    macro avg       0.81      0.81      0.81      3306\n",
      " weighted avg       0.81      0.81      0.81      3306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators= 100 , max_depth= 500 , criterion= 'gini')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application']\n"
     ]
    }
   ],
   "source": [
    "question = 'How many total disk access is needed to search a record using two level indexing?'\n",
    "processed_q = preprocess_text(question)\n",
    "tfidf_q = vectorizer.transform([processed_q])\n",
    "tfidf_q = pd.DataFrame(tfidf_q.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# Adding linguistic features\n",
    "q_ling_features = pd.DataFrame([extract_linguistic_features(question)])\n",
    "\n",
    "# Concatenate DataFrames\n",
    "token_q = pd.concat([q_ling_features, tfidf_q], axis=1)\n",
    "token_q = token_q.drop(columns= ['blooms_verb_present'])\n",
    "\n",
    "print(classifier.predict(token_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How many total disk access is needed to search a record using two level indexing?'\n",
    "inputs =  tokenizer([question], return_tensors='tf', padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings (CLS token for sentence representation)\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_eve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
